{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrutura do AutoEncoder \n",
    "class AutoEncoder(tf.keras.Model):\n",
    "    def __init__(self, latent_dim, im_size=(64, 64), channels=3, **kwargs):\n",
    "        super(AutoEncoder, self).__init__(**kwargs)\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            keras.layers.Input(im_size + (channels,)),\n",
    "            keras.layers.Conv2D(256, 3, padding='same'),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            \n",
    "            keras.layers.Conv2D(128, 3, padding='same'),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            \n",
    "            keras.layers.Conv2D(latent_dim, 3, padding='same', activation='sigmoid'),\n",
    "        ])\n",
    "        \n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            keras.layers.Conv2DTranspose(latent_dim, 3, padding='same'),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            \n",
    "            keras.layers.Conv2DTranspose(128, 3, padding='same'),\n",
    "            keras.layers.LeakyReLU(),            \n",
    "            \n",
    "            keras.layers.Conv2DTranspose(3, 3, padding='same', activation='sigmoid'),\n",
    "        ])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        z = self.encoder(inputs)\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = AutoEncoder(latent_dim=64, im_size=(120, 120))\n",
    "ae.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path):\n",
    "    \"\"\"função para pegar as imagens do diretório especificado\n",
    "    e retornar em formato ndarray em escala de 0 e 1\"\"\"\n",
    "    images = []\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            image = cv2.imread(os.path.join(dirname, filename))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = image.astype('float32')\n",
    "            image /= 255.0\n",
    "            images.append(image)\n",
    "    images = np.array(images)\n",
    "    return images\n",
    "\n",
    "\n",
    "faces_1 = create_dataset('dataset/face_a/')\n",
    "faces_2 = create_dataset('dataset/face_b/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(faces_1, faces_1, test_size=0.20, random_state=0)\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(faces_2, faces_2, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento para o rosto A\n",
    "checkpoint_a = tf.keras.callbacks.ModelCheckpoint('./checkpoints/face_a', save_best_only=True)\n",
    "ae.fit(X_train_a, X_train_a, epochs=1000, validation_data=(X_test_a, X_test_a), batch_size=32, callbacks=[checkpoint_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento para o rosto B\n",
    "checkpoint_b = tf.keras.callbacks.ModelCheckpoint('./checkpoints/face_b', save_best_only=True)\n",
    "ae.fit(X_train_b, X_train_b, epochs=1000, validation_data=(X_test_b, X_test_b), batch_size=32, callbacks=[checkpoint_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando os modelos salvos com os melhores pesos durante o treinamento\n",
    "autoencoder_a = keras.models.load_model('./checkpoints/face_a')\n",
    "autoencoder_b = keras.models.load_model('./checkpoints/face_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pegndo apenas o encoder treinado com o rosto A e o decoder treinado apenas com o rosto B\n",
    "encoder_a = keras.Model(autoencoder_a.encoder.inputs, autoencoder_a.encoder.outputs)\n",
    "decoder_b = keras.Model(autoencoder_b.decoder.inputs, autoencoder_b.decoder.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pegando dois rostos para testar\n",
    "face_a = X_test_a[np.random.randint(X_test_a.shape[0])]\n",
    "face_b = X_test_b[np.random.randint(X_test_b.shape[0])]\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(face_a)\n",
    "plt.title('face a')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(face_b)\n",
    "plt.title('face b')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazendo as transformações\n",
    "face_a_encoded = encoder_a.predict(np.expand_dims(face_a, 0))\n",
    "face_b_decoded = decoder_b.predict(face_a_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Resultado')\n",
    "plt.imshow(face_b_decoded.reshape(120, 120, 3))\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
